{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-25T10:57:07.735036Z",
     "start_time": "2025-04-25T10:57:07.679962Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import warnings"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T10:57:07.991518Z",
     "start_time": "2025-04-25T10:57:07.738448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "files = [\"cleaned.csv\"]\n",
    "dfs = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs, axis=0)"
   ],
   "id": "d02b8d5b9b007c27",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T10:57:08.049125Z",
     "start_time": "2025-04-25T10:57:08.043525Z"
    }
   },
   "cell_type": "code",
   "source": "df['gender'].value_counts()",
   "id": "711a0facbe2ef74c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "male      10345\n",
       "female    10345\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T10:57:08.077926Z",
     "start_time": "2025-04-25T10:57:08.074288Z"
    }
   },
   "cell_type": "code",
   "source": "df['age'].value_counts()",
   "id": "721bcc949ae5c0bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age\n",
       "twenties    14695\n",
       "fifties      5995\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T10:57:08.154187Z",
     "start_time": "2025-04-25T10:57:08.133698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "df['gender'] = df['gender'].map({'male': 0, 'female': 1})\n",
    "df['age'] = df['age'].map({'twenties': 0, 'fifties': 1})\n",
    "print(df.shape)"
   ],
   "id": "2810f87c8de34969",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20690, 107)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T10:57:08.696456Z",
     "start_time": "2025-04-25T10:57:08.198934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def analyze_feature_correlations(df, threshold=0.5):\n",
    "\n",
    "    numeric_df = df.select_dtypes(include=['number'])\n",
    "\n",
    "    corr_matrix = numeric_df.corr()\n",
    "\n",
    "    # Find high correlations\n",
    "    high_corr = []\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "                high_corr.append((corr_matrix.columns[i], corr_matrix.columns[j],\n",
    "                                 corr_matrix.iloc[i, j]))\n",
    "    return high_corr\n",
    "correlated_features = analyze_feature_correlations(df, 0.8)\n",
    "def features_to_keep(all_features, corr_features):\n",
    "    features_set = set()\n",
    "    to_keep = []\n",
    "\n",
    "    for x, y, z in corr_features:\n",
    "        if x not in features_set and y not in features_set:\n",
    "            to_keep.append(x)\n",
    "            features_set.add(x)\n",
    "            features_set.add(y)\n",
    "\n",
    "    for feature in all_features:\n",
    "        if feature not in features_set:\n",
    "            to_keep.append(feature)\n",
    "\n",
    "    return to_keep\n",
    "remaining_features = features_to_keep(df.select_dtypes(include=['number']).columns, correlated_features)\n",
    "remaining_features.append('age')\n",
    "remaining_features.append('gender')\n",
    "remaining_features = list(set(remaining_features))\n",
    "df = df[remaining_features]\n",
    "X = df.drop('gender', axis=1).drop('age',axis=1)\n",
    "print(X.shape, df.shape)"
   ],
   "id": "bdbd6150c4d69c84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20690, 99) (20690, 101)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T10:57:08.721352Z",
     "start_time": "2025-04-25T10:57:08.716089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "def grid_search_sequential(model_gender, model_age,params_gender, params_age, X_reduced,df, proba = False, verbose_level = 2, mode = 'both'):\n",
    "    X_reduced = np.array(X_reduced)\n",
    "    y = np.array(df['gender'] + 2 * df['age'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)\n",
    "    y_train_gender = y_train % 2\n",
    "    y_train_age = y_train // 2\n",
    "    y_test_gender = y_test % 2\n",
    "    y_test_age = y_test // 2\n",
    "    if params_gender is not None:\n",
    "        gender_grid = RandomizedSearchCV(model_gender, param_distributions=params_gender, cv=5, n_jobs=-1, verbose=verbose_level)\n",
    "        gender_grid.fit(X_train, y_train_gender)\n",
    "        gender_classifier = gender_grid.best_estimator_\n",
    "        gender_best_params = gender_grid.best_params_\n",
    "        gender_best_score = gender_grid.best_score_\n",
    "    else:\n",
    "        gender_classifier = model_gender\n",
    "        model_gender.fit(X_train,y_train_gender)\n",
    "        gender_best_score = None\n",
    "        gender_best_params = None\n",
    "    if(mode == 'gender'):\n",
    "        gender_pred_test = gender_classifier.predict(X_test).reshape(-1, 1)\n",
    "        gender_acc = accuracy_score(y_test_gender, gender_pred_test)\n",
    "        print(\"Test set accuracy\", gender_acc)\n",
    "        print(\"Grid Accuracy\", gender_best_score)\n",
    "        return gender_classifier, gender_best_params\n",
    "    ## cross prediction\n",
    "    cv_gender_pred = cross_val_predict(\n",
    "        gender_classifier,\n",
    "        X_train,\n",
    "        y_train_gender,\n",
    "        cv=5,\n",
    "        method='predict_proba' if proba else 'predict'\n",
    "    )\n",
    "\n",
    "    # Format prediction as new feature\n",
    "    if proba:\n",
    "        predicted_gender = cv_gender_pred[:, 1].reshape(-1, 1)\n",
    "    else:\n",
    "        predicted_gender = cv_gender_pred.reshape(-1, 1)\n",
    "    ## concatenate gender\n",
    "    X_train = np.concatenate([X_train, predicted_gender], axis=1)\n",
    "    if params_age is not None:\n",
    "        age_grid = RandomizedSearchCV(model_age, param_distributions=params_age, cv=5, n_jobs=-1, verbose=verbose_level)\n",
    "        age_grid.fit(X_train, y_train_age)\n",
    "        age_classifier = age_grid.best_estimator_\n",
    "        age_best_params = age_grid.best_params_\n",
    "    else:\n",
    "        age_classifier = model_age\n",
    "        model_age.fit(X_train,y_train_age)\n",
    "        age_best_params = None\n",
    "\n",
    "    ### accuracy\n",
    "    gender_pred_test = gender_classifier.predict(X_test).reshape(-1, 1)\n",
    "    gender_acc = accuracy_score(y_test_gender, gender_pred_test)\n",
    "    print(\"Gender Accuracy:\", gender_acc)\n",
    "    if(proba):\n",
    "        gender_proba_test = gender_classifier.predict_proba(X_test)[:,1].reshape(-1, 1)\n",
    "        X_test = np.concatenate([X_test, gender_proba_test], axis=1)\n",
    "    else:\n",
    "        X_test = np.concatenate([X_test, gender_pred_test], axis=1)\n",
    "    age_pred_test = age_classifier.predict(X_test).reshape(-1, 1)\n",
    "    age_acc = accuracy_score(y_test_age, age_pred_test)\n",
    "    print(\"Age Accuracy:\", age_acc)\n",
    "\n",
    "    gender_age = gender_pred_test + 2 * age_pred_test\n",
    "    total_acc = accuracy_score(gender_age, y_test)\n",
    "\n",
    "    print(\"Total Accuracy:\", total_acc)\n",
    "\n",
    "    return gender_classifier, age_classifier, gender_best_params, age_best_params, total_acc"
   ],
   "id": "2c4db2d594cc0992",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T10:57:08.732676Z",
     "start_time": "2025-04-25T10:57:08.730324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_gender_age(model_gender, model_age, X, proba):\n",
    "    gender = model_gender.predict(X).reshape(-1, 1)\n",
    "    if(proba):\n",
    "        gender_proba = model_gender.predict_proba(X)[:,1].reshape(-1, 1)\n",
    "        X = np.concatenate([X, gender_proba], axis=1)\n",
    "    else:\n",
    "        X = np.concatenate([X, gender], axis = 1)\n",
    "    age = model_age.predict(X).reshape(-1, 1)\n",
    "    return (gender + 2 * age).flatten()"
   ],
   "id": "c580261604b89599",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Sequential Accuracy with the result gender (not proba)\n",
    "Gender 0.88, age = 0.81, both 0.74"
   ],
   "id": "ddd686aac8b297ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Sequential Accuracy with the result gender proba both 73, age worse than above 0.73\n",
   "id": "944414f42b4f3d0e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After CHANGING the grid search for more features =>",
   "id": "d7845b8773d92147"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T11:10:31.845209Z",
     "start_time": "2025-04-25T10:57:08.762310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from Linear_Model_Tree import LinearModelTree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "et = ExtraTreesClassifier()\n",
    "params_dict = {\n",
    "    'et': {\n",
    "        'n_estimators': [500,1000,1500,2000,2500],\n",
    "        'max_depth': [None, 5, 10, 20,30,50],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2',15,20,25,30,35,40],\n",
    "    }\n",
    "}\n",
    "model_g, model_a, params_g, params_a, total = grid_search_sequential(et, et, params_dict['et'], params_dict['et'], X, df, proba = True, verbose_level = 2, mode = 'both')"
   ],
   "id": "24fd2925e42fa0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END max_depth=50, max_features=25, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=  25.8s\n",
      "[CV] END max_depth=30, max_features=40, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time=  37.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1500; total time=  16.7s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=  17.9s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time=  13.3s\n",
      "[CV] END max_depth=5, max_features=25, min_samples_leaf=2, min_samples_split=2, n_estimators=1500; total time=  15.3s\n",
      "[CV] END max_depth=10, max_features=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1500; total time=  40.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.4s\n",
      "[CV] END max_depth=30, max_features=40, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time=  37.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1500; total time=  17.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1500; total time=  16.4s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=  17.9s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time=  13.0s\n",
      "[CV] END max_depth=10, max_features=35, min_samples_leaf=4, min_samples_split=10, n_estimators=2500; total time=  59.2s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.6s\n",
      "[CV] END max_depth=30, max_features=40, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time=  35.7s\n",
      "[CV] END max_depth=20, max_features=40, min_samples_leaf=1, min_samples_split=2, n_estimators=1500; total time= 1.0min\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time=  12.7s\n",
      "[CV] END max_depth=10, max_features=35, min_samples_leaf=4, min_samples_split=10, n_estimators=2500; total time=  58.4s\n",
      "[CV] END max_depth=50, max_features=25, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=  26.1s\n",
      "[CV] END max_depth=20, max_features=40, min_samples_leaf=1, min_samples_split=2, n_estimators=1500; total time= 1.0min\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=  18.1s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time=  13.4s\n",
      "[CV] END max_depth=10, max_features=35, min_samples_leaf=4, min_samples_split=10, n_estimators=2500; total time=  58.6s\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1500; total time=   6.8s\n",
      "[CV] END max_depth=None, max_features=30, min_samples_leaf=4, min_samples_split=5, n_estimators=2500; total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=50, max_features=25, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=  25.7s\n",
      "[CV] END max_depth=20, max_features=40, min_samples_leaf=1, min_samples_split=2, n_estimators=1500; total time= 1.0min\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=  17.9s\n",
      "[CV] END max_depth=5, max_features=25, min_samples_leaf=2, min_samples_split=2, n_estimators=1500; total time=  15.8s\n",
      "[CV] END max_depth=10, max_features=35, min_samples_leaf=4, min_samples_split=10, n_estimators=2500; total time=  58.0s\n",
      "[CV] END max_depth=20, max_features=20, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  12.3s\n",
      "[CV] END max_depth=None, max_features=30, min_samples_leaf=4, min_samples_split=5, n_estimators=2500; total time= 1.4min\n",
      "[CV] END max_depth=50, max_features=25, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=  26.0s\n",
      "[CV] END max_depth=20, max_features=40, min_samples_leaf=1, min_samples_split=2, n_estimators=1500; total time= 1.1min\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=  18.0s\n",
      "[CV] END max_depth=5, max_features=25, min_samples_leaf=2, min_samples_split=2, n_estimators=1500; total time=  16.2s\n",
      "[CV] END max_depth=10, max_features=35, min_samples_leaf=4, min_samples_split=10, n_estimators=2500; total time=  57.5s\n",
      "[CV] END max_depth=20, max_features=20, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  12.2s\n",
      "[CV] END max_depth=None, max_features=30, min_samples_leaf=4, min_samples_split=5, n_estimators=2500; total time= 1.4min\n",
      "[CV] END max_depth=50, max_features=25, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=  25.7s\n",
      "[CV] END max_depth=30, max_features=40, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time=  37.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1500; total time=  16.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1500; total time=  17.1s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time=  13.1s\n",
      "[CV] END max_depth=5, max_features=25, min_samples_leaf=2, min_samples_split=2, n_estimators=1500; total time=  15.1s\n",
      "[CV] END max_depth=10, max_features=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1500; total time=  40.9s\n",
      "[CV] END max_depth=10, max_features=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1500; total time=  31.3s\n",
      "[CV] END max_depth=20, max_features=20, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  12.1s\n",
      "[CV] END max_depth=None, max_features=30, min_samples_leaf=4, min_samples_split=5, n_estimators=2500; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=30, max_features=40, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time=  35.6s\n",
      "[CV] END max_depth=20, max_features=40, min_samples_leaf=1, min_samples_split=2, n_estimators=1500; total time= 1.0min\n",
      "[CV] END max_depth=5, max_features=25, min_samples_leaf=2, min_samples_split=2, n_estimators=1500; total time=  14.9s\n",
      "[CV] END max_depth=10, max_features=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1500; total time=  41.0s\n",
      "[CV] END max_depth=10, max_features=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1500; total time=  31.0s\n",
      "[CV] END max_depth=20, max_features=20, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  12.3s\n",
      "[CV] END max_depth=None, max_features=30, min_samples_leaf=4, min_samples_split=5, n_estimators=2500; total time= 1.4min\n",
      "[CV] END max_depth=20, max_features=20, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  12.0s\n",
      "[CV] END max_depth=20, max_features=30, min_samples_leaf=2, min_samples_split=5, n_estimators=2500; total time= 1.5min\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1500; total time=   6.7s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1500; total time=   6.8s\n",
      "[CV] END max_depth=20, max_features=30, min_samples_leaf=2, min_samples_split=5, n_estimators=2500; total time= 1.5min\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1500; total time=   6.7s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1500; total time=   6.6s\n",
      "[CV] END max_depth=20, max_features=30, min_samples_leaf=2, min_samples_split=5, n_estimators=2500; total time= 1.5min\n",
      "Gender Accuracy: 0.9509424842919285\n",
      "Age Accuracy: 0.8668438859352344\n",
      "Total Accuracy: 0.8320444659255679\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T11:10:31.916827Z",
     "start_time": "2025-04-25T11:10:31.913478Z"
    }
   },
   "cell_type": "code",
   "source": "print(params_g, params_a, total)",
   "id": "bc5d13167860eb1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 40, 'max_depth': 20} {'n_estimators': 2000, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 35, 'max_depth': 50} 0.8320444659255679\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T11:16:26.013292Z",
     "start_time": "2025-04-25T11:10:31.954486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_reduced = np.array(X)\n",
    "y = np.array(df['gender'] + 2 * df['age'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)\n",
    "combined_grid = RandomizedSearchCV(et, param_distributions=params_dict['et'], cv=5, n_jobs=-1, verbose=2)\n",
    "combined_grid.fit(X_train, y_train)\n",
    "best_combined_model = combined_grid.best_estimator_\n",
    "best_combined_params = combined_grid.best_params_\n",
    "best_combined_score = combined_grid.best_score_\n",
    "print(\"Best parameters:\", best_combined_params)\n",
    "print(\"Best score:\", best_combined_score)\n",
    "print(\"Test set accuracy:\", best_combined_model.score(X_test, y_test))"
   ],
   "id": "93f1d071cf3fb37e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END max_depth=50, max_features=35, min_samples_leaf=2, min_samples_split=5, n_estimators=2000; total time= 1.4min\n",
      "[CV] END max_depth=5, max_features=35, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   6.2s\n",
      "[CV] END max_depth=5, max_features=35, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   6.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=2000; total time=  34.4s\n",
      "[CV] END max_depth=50, max_features=30, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time= 1.4min\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1500; total time=  21.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time=  12.4s\n",
      "[CV] END max_depth=50, max_features=20, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=  28.4s\n",
      "[CV] END max_depth=50, max_features=20, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=  28.2s\n",
      "[CV] END max_depth=50, max_features=20, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=  28.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=2000; total time=  34.4s\n",
      "[CV] END max_depth=None, max_features=20, min_samples_leaf=4, min_samples_split=5, n_estimators=2000; total time=  53.2s\n",
      "[CV] END max_depth=None, max_features=20, min_samples_leaf=4, min_samples_split=5, n_estimators=2000; total time=  53.4s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1500; total time=  21.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time=  12.4s\n",
      "[CV] END max_depth=50, max_features=35, min_samples_leaf=2, min_samples_split=5, n_estimators=2000; total time= 1.4min\n",
      "[CV] END max_depth=5, max_features=35, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   6.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=2000; total time=  34.4s\n",
      "[CV] END max_depth=None, max_features=20, min_samples_leaf=4, min_samples_split=5, n_estimators=2000; total time=  53.5s\n",
      "[CV] END max_depth=None, max_features=20, min_samples_leaf=4, min_samples_split=5, n_estimators=2000; total time=  53.5s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1500; total time=  21.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=2000; total time=   9.2s\n",
      "[CV] END max_depth=30, max_features=35, min_samples_leaf=1, min_samples_split=10, n_estimators=1500; total time= 1.0min\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=2000; total time=   9.4s\n",
      "[CV] END max_depth=5, max_features=35, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=  11.7s\n",
      "[CV] END max_depth=5, max_features=35, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=  11.7s\n",
      "[CV] END max_depth=30, max_features=20, min_samples_leaf=2, min_samples_split=5, n_estimators=1500; total time=  47.9s\n",
      "Best parameters: {'n_estimators': 1500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 35, 'max_depth': 50}\n",
      "Best score: 0.8421329615371631\n",
      "Test set accuracy: 0.8419526341227647\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-25T11:16:26.058970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "KNN = KNeighborsClassifier()\n",
    "knn_params = {\n",
    "    'n_neighbors': [1, 3, 5, 7, 9, 11,13,15,17,19,21],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "}\n",
    "_, model_a_knn, _, params_a_knn, total_knn = grid_search_sequential(model_g, KNN, None, knn_params, X, df, proba = False, verbose_level = 2, mode = 'both')\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_params = {\n",
    "    'n_estimators': [10, 20, 50, 100,300,500,700,1000, 1500],\n",
    "    'max_depth': [None, 5, 10, 20,30,50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2',15,20,25,30,35,40],\n",
    "}\n",
    "_, model_a_rf, _, params_a_rf, total_rf = grid_search_sequential(model_g, rf, None, rf_params, X, df, proba = False, verbose_level = 2, mode = 'both')\n",
    "\n",
    "\n",
    "print(\"Best parameters for KNN:\", params_a_knn)\n",
    "print(\"Best parameters for RF:\", params_a_rf)\n",
    "print(\"Best parameters for ET:\", params_a)\n",
    "print(\"Best score for KNN:\", total_knn)\n",
    "print(\"Best score for RF:\", total_rf)\n",
    "print(\"Best score for ET:\", total)\n",
    "print(\"Test set accuracy for KNN:\", model_a_knn.score(X_test, y_test))\n",
    "print(\"Test set accuracy for RF:\", model_a_rf.score(X_test, y_test))\n",
    "print(\"Test set accuracy for ET:\", model_a.score(X_test, y_test))\n"
   ],
   "id": "4199fd6297aa9309",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "svm = SVC(probability=True)\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10, 100,1000, 10000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree': [2, 3, 4],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "}\n",
    "_, model_a_svm, _, params_a_svm, total_svm = grid_search_sequential(model_g, svm, None, svm_params, X, df, proba = False, verbose_level = 2, mode = 'both')\n",
    "print(\"Best parameters for SVM:\", params_a_svm)\n",
    "print(\"Best score for SVM:\", total_svm)\n",
    "print(\"Test set accuracy for SVM:\", model_a_svm.score(X_test, y_test))\n"
   ],
   "id": "596b26b2d10e877a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "lr_params = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "}\n",
    "base_estimators = [\n",
    "    ('knn', model_a_knn),\n",
    "    ('rf', model_a_rf),\n",
    "    ('et', model_a),\n",
    "    ('svc', model_a_svm),\n",
    "]\n",
    "meta_classifier = LogisticRegression(max_iter=1000)\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=base_estimators,\n",
    "    final_estimator=meta_classifier,\n",
    "    cv=5,\n",
    "    stack_method='auto',\n",
    "    n_jobs=-1\n",
    ")\n",
    "stacking_clf.fit(X_train, y_train // 2)"
   ],
   "id": "5117dc286904c643",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "stacking_pred = stacking_clf.predict(X_test)\n",
    "stacking_acc = accuracy_score(y_test // 2, stacking_pred)\n",
    "print(\"Stacking Classifier Age Accuracy:\", stacking_acc)\n",
    "y_pred_test = stacking_clf.predict(X_test) * 2 + model_g.predict(X_test)\n",
    "print(\"Stacking Classifier Total Accuracy:\", accuracy_score(y_test, y_pred_test))"
   ],
   "id": "ddc2864c56535632",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a2786dd1d39af084",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
