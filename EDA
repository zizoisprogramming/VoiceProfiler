{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11530342,"sourceType":"datasetVersion","datasetId":7232074}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler, PowerTransformer, RobustScaler\nfrom scipy.stats import skew\nfrom matplotlib.gridspec import GridSpec\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:15:42.234324Z","iopub.execute_input":"2025-04-23T19:15:42.234773Z","iopub.status.idle":"2025-04-23T19:15:42.240249Z","shell.execute_reply.started":"2025-04-23T19:15:42.234740Z","shell.execute_reply":"2025-04-23T19:15:42.239079Z"}},"outputs":[],"execution_count":617},{"cell_type":"code","source":"features = pd.read_csv(\"/kaggle/input/voice-features/features.csv\")\nextra_features = pd.read_csv(\"/kaggle/input/voice-features/extracted_features_2k_3.csv\")\nassert (features.columns == extra_features.columns).all() == True, 'mismatch in features'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:15:51.354488Z","iopub.execute_input":"2025-04-23T19:15:51.354869Z","iopub.status.idle":"2025-04-23T19:15:51.602242Z","shell.execute_reply.started":"2025-04-23T19:15:51.354845Z","shell.execute_reply":"2025-04-23T19:15:51.601439Z"}},"outputs":[],"execution_count":618},{"cell_type":"code","source":"def get_data_again():\n    return pd.concat([features, extra_features])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:15:51.681345Z","iopub.execute_input":"2025-04-23T19:15:51.681662Z","iopub.status.idle":"2025-04-23T19:15:51.686599Z","shell.execute_reply.started":"2025-04-23T19:15:51.681642Z","shell.execute_reply":"2025-04-23T19:15:51.685753Z"}},"outputs":[],"execution_count":619},{"cell_type":"code","source":"df = get_data_again()\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:15:52.179251Z","iopub.execute_input":"2025-04-23T19:15:52.179585Z","iopub.status.idle":"2025-04-23T19:15:52.207127Z","shell.execute_reply.started":"2025-04-23T19:15:52.179562Z","shell.execute_reply":"2025-04-23T19:15:52.206263Z"}},"outputs":[{"execution_count":620,"output_type":"execute_result","data":{"text/plain":"   duration       wps    f0_mean     f0_std  f0_5_percentile  \\\n0     3.624  2.483444  43.679260   7.371807        34.668420   \n1     8.280  1.690821  53.686158   7.416054        44.160759   \n2     3.360  1.190476  41.534685   3.806376        34.448272   \n3     5.472  1.279240  54.116891  12.613461        36.077473   \n4     5.016  1.993620  63.434174  16.955869        46.759747   \n\n   f0_95_percentile     tempo     formant1     formant2     formant3  ...  \\\n0         58.085883  4.966887   684.276613  2144.732066  3551.312656  ...   \n1         67.459444  5.676329   528.719302  1327.511601  2695.891257  ...   \n2         47.604511  3.571429   629.261116  1991.730144  3142.621149  ...   \n3         77.781746  3.472222  1730.391551  2606.610018  3787.764806  ...   \n4         89.347764  5.781499  1494.218061  2488.452628  3367.597097  ...   \n\n   mfcc_11_skewness  mfcc_12_skewness  cpp_mean  ste_mean   ste_std  \\\n0         -0.573998         -0.847324  0.078587  0.930276  0.990859   \n1          0.231403         -0.113490  0.080541  1.806639  1.874120   \n2         -0.204671         -0.059365  0.058467  0.223676  0.146010   \n3         -1.046761         -0.800392  0.046990  1.106869  1.276842   \n4         -0.219653         -0.237146  0.104711  6.937383  7.923952   \n\n     ste_max   ste_min  ste_variance  gender       age  \n0   5.593383  0.065408      0.981801    male  twenties  \n1  10.059046  0.065434      3.512328    male  twenties  \n2   0.622285  0.044940      0.021319    male   fifties  \n3   6.991178  0.058588      1.630326    male   fifties  \n4  62.147619  0.052917     62.789019    male  twenties  \n\n[5 rows x 122 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration</th>\n      <th>wps</th>\n      <th>f0_mean</th>\n      <th>f0_std</th>\n      <th>f0_5_percentile</th>\n      <th>f0_95_percentile</th>\n      <th>tempo</th>\n      <th>formant1</th>\n      <th>formant2</th>\n      <th>formant3</th>\n      <th>...</th>\n      <th>mfcc_11_skewness</th>\n      <th>mfcc_12_skewness</th>\n      <th>cpp_mean</th>\n      <th>ste_mean</th>\n      <th>ste_std</th>\n      <th>ste_max</th>\n      <th>ste_min</th>\n      <th>ste_variance</th>\n      <th>gender</th>\n      <th>age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.624</td>\n      <td>2.483444</td>\n      <td>43.679260</td>\n      <td>7.371807</td>\n      <td>34.668420</td>\n      <td>58.085883</td>\n      <td>4.966887</td>\n      <td>684.276613</td>\n      <td>2144.732066</td>\n      <td>3551.312656</td>\n      <td>...</td>\n      <td>-0.573998</td>\n      <td>-0.847324</td>\n      <td>0.078587</td>\n      <td>0.930276</td>\n      <td>0.990859</td>\n      <td>5.593383</td>\n      <td>0.065408</td>\n      <td>0.981801</td>\n      <td>male</td>\n      <td>twenties</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8.280</td>\n      <td>1.690821</td>\n      <td>53.686158</td>\n      <td>7.416054</td>\n      <td>44.160759</td>\n      <td>67.459444</td>\n      <td>5.676329</td>\n      <td>528.719302</td>\n      <td>1327.511601</td>\n      <td>2695.891257</td>\n      <td>...</td>\n      <td>0.231403</td>\n      <td>-0.113490</td>\n      <td>0.080541</td>\n      <td>1.806639</td>\n      <td>1.874120</td>\n      <td>10.059046</td>\n      <td>0.065434</td>\n      <td>3.512328</td>\n      <td>male</td>\n      <td>twenties</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.360</td>\n      <td>1.190476</td>\n      <td>41.534685</td>\n      <td>3.806376</td>\n      <td>34.448272</td>\n      <td>47.604511</td>\n      <td>3.571429</td>\n      <td>629.261116</td>\n      <td>1991.730144</td>\n      <td>3142.621149</td>\n      <td>...</td>\n      <td>-0.204671</td>\n      <td>-0.059365</td>\n      <td>0.058467</td>\n      <td>0.223676</td>\n      <td>0.146010</td>\n      <td>0.622285</td>\n      <td>0.044940</td>\n      <td>0.021319</td>\n      <td>male</td>\n      <td>fifties</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.472</td>\n      <td>1.279240</td>\n      <td>54.116891</td>\n      <td>12.613461</td>\n      <td>36.077473</td>\n      <td>77.781746</td>\n      <td>3.472222</td>\n      <td>1730.391551</td>\n      <td>2606.610018</td>\n      <td>3787.764806</td>\n      <td>...</td>\n      <td>-1.046761</td>\n      <td>-0.800392</td>\n      <td>0.046990</td>\n      <td>1.106869</td>\n      <td>1.276842</td>\n      <td>6.991178</td>\n      <td>0.058588</td>\n      <td>1.630326</td>\n      <td>male</td>\n      <td>fifties</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.016</td>\n      <td>1.993620</td>\n      <td>63.434174</td>\n      <td>16.955869</td>\n      <td>46.759747</td>\n      <td>89.347764</td>\n      <td>5.781499</td>\n      <td>1494.218061</td>\n      <td>2488.452628</td>\n      <td>3367.597097</td>\n      <td>...</td>\n      <td>-0.219653</td>\n      <td>-0.237146</td>\n      <td>0.104711</td>\n      <td>6.937383</td>\n      <td>7.923952</td>\n      <td>62.147619</td>\n      <td>0.052917</td>\n      <td>62.789019</td>\n      <td>male</td>\n      <td>twenties</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 122 columns</p>\n</div>"},"metadata":{}}],"execution_count":620},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:15:53.338644Z","iopub.execute_input":"2025-04-23T19:15:53.339390Z","iopub.status.idle":"2025-04-23T19:15:53.579292Z","shell.execute_reply.started":"2025-04-23T19:15:53.339361Z","shell.execute_reply":"2025-04-23T19:15:53.578320Z"}},"outputs":[{"execution_count":621,"output_type":"execute_result","data":{"text/plain":"          duration          wps      f0_mean       f0_std  f0_5_percentile  \\\ncount  8708.000000  8708.000000  8708.000000  8708.000000      8708.000000   \nmean      4.780975     1.976009   114.212174    98.384737        50.904282   \nstd       1.748564     0.530231   148.919355   228.421469        36.991394   \nmin       2.016000     0.318066    32.731152     0.000000        32.703196   \n25%       3.456000     1.612103    55.894862     9.790454        36.896821   \n50%       4.584000     1.929012    72.443927    15.971007        45.114880   \n75%       5.904000     2.289377   101.419702    30.814357        58.073297   \nmax      56.184000     7.575758  2720.371358  1867.523201      2400.829293   \n\n       f0_95_percentile        tempo     formant1     formant2     formant3  \\\ncount       8708.000000  8708.000000  8708.000000  8708.000000  8708.000000   \nmean         333.737052     5.039624   687.211164  1833.334821  2883.519413   \nstd          661.893918     1.271568   441.433150   545.934084   543.602292   \nmin           32.703196     0.345304    53.055715   331.194681  1073.407097   \n25%           73.416192     4.201681   395.174270  1467.230770  2536.355263   \n50%          102.042503     5.050505   534.138272  1796.395020  2838.562609   \n75%          145.986692     5.853994   818.248114  2160.262578  3201.790421   \nmax         3898.936015    14.735772  3034.412533  4169.661749  5437.159199   \n\n       ...  mfcc_9_skewness  mfcc_10_skewness  mfcc_11_skewness  \\\ncount  ...      8708.000000       8708.000000       8708.000000   \nmean   ...        -0.441365         -0.267753         -0.347137   \nstd    ...         0.484152          0.522339          0.460726   \nmin    ...        -2.721835         -2.717453         -2.370532   \n25%    ...        -0.739966         -0.601477         -0.628384   \n50%    ...        -0.473651         -0.305432         -0.365897   \n75%    ...        -0.180985          0.051344         -0.084060   \nmax    ...         2.082980          3.992950          2.612354   \n\n       mfcc_12_skewness     cpp_mean     ste_mean      ste_std      ste_max  \\\ncount       8708.000000  8708.000000  8708.000000  8708.000000  8708.000000   \nmean          -0.254184     0.093265     6.436285     7.667566    39.084639   \nstd            0.507711     0.028211     6.755611     7.547738    36.144699   \nmin           -2.583461    -0.022723     0.057446     0.000000     0.057446   \n25%           -0.586020     0.074232     1.613715     1.814349     9.625515   \n50%           -0.286813     0.089841     5.085478     6.281752    32.436849   \n75%            0.062437     0.109095     8.821161    10.992443    57.936166   \nmax            2.549911     0.365094   125.336596    86.538039   485.515156   \n\n           ste_min  ste_variance  \ncount  8708.000000   8708.000000  \nmean      0.070181    115.753366  \nstd       0.025010    302.931014  \nmin       0.033304      0.000000  \n25%       0.060510      3.291863  \n50%       0.066101     39.460406  \n75%       0.073823    120.833811  \nmax       0.755335   7488.832142  \n\n[8 rows x 120 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration</th>\n      <th>wps</th>\n      <th>f0_mean</th>\n      <th>f0_std</th>\n      <th>f0_5_percentile</th>\n      <th>f0_95_percentile</th>\n      <th>tempo</th>\n      <th>formant1</th>\n      <th>formant2</th>\n      <th>formant3</th>\n      <th>...</th>\n      <th>mfcc_9_skewness</th>\n      <th>mfcc_10_skewness</th>\n      <th>mfcc_11_skewness</th>\n      <th>mfcc_12_skewness</th>\n      <th>cpp_mean</th>\n      <th>ste_mean</th>\n      <th>ste_std</th>\n      <th>ste_max</th>\n      <th>ste_min</th>\n      <th>ste_variance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>8708.000000</td>\n      <td>8708.000000</td>\n      <td>8708.000000</td>\n      <td>8708.000000</td>\n      <td>8708.000000</td>\n      <td>8708.000000</td>\n      <td>8708.000000</td>\n      <td>8708.000000</td>\n      <td>8708.000000</td>\n      <td>8708.000000</td>\n      <td>...</td>\n      <td>8708.000000</td>\n      <td>8708.000000</td>\n      <td>8708.000000</td>\n      <td>8708.000000</td>\n      <td>8708.000000</td>\n      <td>8708.000000</td>\n      <td>8708.000000</td>\n      <td>8708.000000</td>\n      <td>8708.000000</td>\n      <td>8708.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.780975</td>\n      <td>1.976009</td>\n      <td>114.212174</td>\n      <td>98.384737</td>\n      <td>50.904282</td>\n      <td>333.737052</td>\n      <td>5.039624</td>\n      <td>687.211164</td>\n      <td>1833.334821</td>\n      <td>2883.519413</td>\n      <td>...</td>\n      <td>-0.441365</td>\n      <td>-0.267753</td>\n      <td>-0.347137</td>\n      <td>-0.254184</td>\n      <td>0.093265</td>\n      <td>6.436285</td>\n      <td>7.667566</td>\n      <td>39.084639</td>\n      <td>0.070181</td>\n      <td>115.753366</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.748564</td>\n      <td>0.530231</td>\n      <td>148.919355</td>\n      <td>228.421469</td>\n      <td>36.991394</td>\n      <td>661.893918</td>\n      <td>1.271568</td>\n      <td>441.433150</td>\n      <td>545.934084</td>\n      <td>543.602292</td>\n      <td>...</td>\n      <td>0.484152</td>\n      <td>0.522339</td>\n      <td>0.460726</td>\n      <td>0.507711</td>\n      <td>0.028211</td>\n      <td>6.755611</td>\n      <td>7.547738</td>\n      <td>36.144699</td>\n      <td>0.025010</td>\n      <td>302.931014</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2.016000</td>\n      <td>0.318066</td>\n      <td>32.731152</td>\n      <td>0.000000</td>\n      <td>32.703196</td>\n      <td>32.703196</td>\n      <td>0.345304</td>\n      <td>53.055715</td>\n      <td>331.194681</td>\n      <td>1073.407097</td>\n      <td>...</td>\n      <td>-2.721835</td>\n      <td>-2.717453</td>\n      <td>-2.370532</td>\n      <td>-2.583461</td>\n      <td>-0.022723</td>\n      <td>0.057446</td>\n      <td>0.000000</td>\n      <td>0.057446</td>\n      <td>0.033304</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>3.456000</td>\n      <td>1.612103</td>\n      <td>55.894862</td>\n      <td>9.790454</td>\n      <td>36.896821</td>\n      <td>73.416192</td>\n      <td>4.201681</td>\n      <td>395.174270</td>\n      <td>1467.230770</td>\n      <td>2536.355263</td>\n      <td>...</td>\n      <td>-0.739966</td>\n      <td>-0.601477</td>\n      <td>-0.628384</td>\n      <td>-0.586020</td>\n      <td>0.074232</td>\n      <td>1.613715</td>\n      <td>1.814349</td>\n      <td>9.625515</td>\n      <td>0.060510</td>\n      <td>3.291863</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>4.584000</td>\n      <td>1.929012</td>\n      <td>72.443927</td>\n      <td>15.971007</td>\n      <td>45.114880</td>\n      <td>102.042503</td>\n      <td>5.050505</td>\n      <td>534.138272</td>\n      <td>1796.395020</td>\n      <td>2838.562609</td>\n      <td>...</td>\n      <td>-0.473651</td>\n      <td>-0.305432</td>\n      <td>-0.365897</td>\n      <td>-0.286813</td>\n      <td>0.089841</td>\n      <td>5.085478</td>\n      <td>6.281752</td>\n      <td>32.436849</td>\n      <td>0.066101</td>\n      <td>39.460406</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>5.904000</td>\n      <td>2.289377</td>\n      <td>101.419702</td>\n      <td>30.814357</td>\n      <td>58.073297</td>\n      <td>145.986692</td>\n      <td>5.853994</td>\n      <td>818.248114</td>\n      <td>2160.262578</td>\n      <td>3201.790421</td>\n      <td>...</td>\n      <td>-0.180985</td>\n      <td>0.051344</td>\n      <td>-0.084060</td>\n      <td>0.062437</td>\n      <td>0.109095</td>\n      <td>8.821161</td>\n      <td>10.992443</td>\n      <td>57.936166</td>\n      <td>0.073823</td>\n      <td>120.833811</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>56.184000</td>\n      <td>7.575758</td>\n      <td>2720.371358</td>\n      <td>1867.523201</td>\n      <td>2400.829293</td>\n      <td>3898.936015</td>\n      <td>14.735772</td>\n      <td>3034.412533</td>\n      <td>4169.661749</td>\n      <td>5437.159199</td>\n      <td>...</td>\n      <td>2.082980</td>\n      <td>3.992950</td>\n      <td>2.612354</td>\n      <td>2.549911</td>\n      <td>0.365094</td>\n      <td>125.336596</td>\n      <td>86.538039</td>\n      <td>485.515156</td>\n      <td>0.755335</td>\n      <td>7488.832142</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 120 columns</p>\n</div>"},"metadata":{}}],"execution_count":621},{"cell_type":"code","source":"def check_nulls(df):\n    a = df.isna().sum()\n    for index, value in a.items():\n        if value > 0:\n            return False\n    return True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:15:53.921078Z","iopub.execute_input":"2025-04-23T19:15:53.921914Z","iopub.status.idle":"2025-04-23T19:15:53.926583Z","shell.execute_reply.started":"2025-04-23T19:15:53.921879Z","shell.execute_reply":"2025-04-23T19:15:53.925532Z"}},"outputs":[],"execution_count":622},{"cell_type":"code","source":"def smart_normalize(df, skew_threshold=0.5):\n\n    numeric_cols = df.select_dtypes(include=['number']).columns\n    df_normalized = df.copy()\n    transformations = {}\n    \n    # Step 1: Skewness correction\n    for col in numeric_cols:\n        col_skew = skew(df[col].dropna())\n        if abs(col_skew) > skew_threshold:\n            # Apply Yeo-Johnson power transform (handles positive/negative values)\n            pt = PowerTransformer(method='yeo-johnson')\n            df_normalized[col] = pt.fit_transform(df[[col]]).flatten()\n            transformations[col] = {\n                'step1': 'power_transform',\n                'skewness': col_skew,\n                'transformer': pt\n            }\n        else:\n            transformations[col] = {\n                'step1': 'none',\n                'skewness': col_skew\n            }\n    \n    # Step 2: Standard scaling (applied to all numeric columns)\n    scaler = StandardScaler()\n    df_normalized[numeric_cols] = scaler.fit_transform(df_normalized[numeric_cols])\n    transformations['_standard_scaler'] = scaler\n    \n    return df_normalized, transformations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:15:54.478510Z","iopub.execute_input":"2025-04-23T19:15:54.479378Z","iopub.status.idle":"2025-04-23T19:15:54.485993Z","shell.execute_reply.started":"2025-04-23T19:15:54.479348Z","shell.execute_reply":"2025-04-23T19:15:54.485010Z"}},"outputs":[],"execution_count":623},{"cell_type":"code","source":"def remove_outliers(df, outliers_cols, threshold_percent = 1):\n    numeric_cols = df.select_dtypes(include=['number']).columns\n    df_clean = df.copy()\n    \n    for i, (col, states) in enumerate(outliers_cols.items()):\n        if states['percent'] < threshold_percent:\n            lower_bound = states['lower_bound']\n            upper_bound = states['upper_bound']\n            \n            df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n        \n    return df_clean","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:15:55.543234Z","iopub.execute_input":"2025-04-23T19:15:55.543578Z","iopub.status.idle":"2025-04-23T19:15:55.549867Z","shell.execute_reply.started":"2025-04-23T19:15:55.543555Z","shell.execute_reply":"2025-04-23T19:15:55.548908Z"}},"outputs":[],"execution_count":624},{"cell_type":"code","source":"def find_high_outlier_columns(df):\n    outlier_columns = {}\n    \n    for col in df.select_dtypes(include=np.number).columns:\n        if col == 'age' or df[col].nunique() < 10:  \n            continue\n            \n        Q1 = df[col].quantile(0.1)\n        Q3 = df[col].quantile(0.9)\n        IQR = Q3 - Q1\n        \n        lower_bound = Q1 - 1.5 * IQR\n        upper_bound = Q3 + 1.5 * IQR\n        \n        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]\n        outlier_percent = (len(outliers) / len(df[col].dropna())) * 100\n        \n        outlier_columns[col] = {\n            'percent': outlier_percent,\n            'count': len(outliers),\n            'lower_bound': lower_bound,\n            'upper_bound': upper_bound\n        }\n            \n    return outlier_columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:15:55.820916Z","iopub.execute_input":"2025-04-23T19:15:55.821576Z","iopub.status.idle":"2025-04-23T19:15:55.828348Z","shell.execute_reply.started":"2025-04-23T19:15:55.821547Z","shell.execute_reply":"2025-04-23T19:15:55.827408Z"}},"outputs":[],"execution_count":625},{"cell_type":"code","source":"def visualize_outliers(df, outlier_columns):\n    if not outlier_columns:\n        print(\"No columns with more than 5% outliers found.\")\n        return\n        \n    for i, (col, stats) in enumerate(outlier_columns.items()):\n        if stats['percent'] > 5:\n            plt.figure(figsize=(15, 8))\n            gs = GridSpec(2, 2, height_ratios=[3, 1])\n            \n            # Box plot\n            ax1 = plt.subplot(gs[0, 0])\n            sns.boxplot(x=df[col], ax=ax1)\n            ax1.set_title(f\"Box Plot: {col}\")\n            \n            # Histogram with KDE\n            ax2 = plt.subplot(gs[0, 1])\n            sns.histplot(df[col], kde=True, ax=ax2)\n            ax2.axvline(stats['lower_bound'], color='r', linestyle='--', label='Outlier Threshold')\n            ax2.axvline(stats['upper_bound'], color='r', linestyle='--')\n            ax2.legend()\n            ax2.set_title(f\"Distribution: {col}\")\n            \n            # Outlier detail table\n            ax3 = plt.subplot(gs[1, :])\n            ax3.axis('off')\n            outlier_text = (\n                f\"Column: {col}\\n\"\n                f\"Outliers: {stats['count']} values ({stats['percent']:.2f}% of non-null data)\\n\"\n                f\"Lower bound: {stats['lower_bound']:.2f}\\n\"\n                f\"Upper bound: {stats['upper_bound']:.2f}\\n\"\n                f\"Min: {df[col].min():.2f}, Max: {df[col].max():.2f}\\n\"\n                f\"Mean: {df[col].mean():.2f}, Median: {df[col].median():.2f}\"\n            )\n            ax3.text(0.5, 0.5, outlier_text, ha='center', va='center', fontsize=12)\n            \n            plt.tight_layout()\n            plt.show()\n            \n            # Print summary\n            print(f\"\\nðŸ“Š Outlier Analysis for {col}:\")\n            print(f\"  â€¢ {stats['percent']:.2f}% of values are outliers ({stats['count']} out of {len(df[col].dropna())})\")\n            print(f\"  â€¢ Outlier thresholds: < {stats['lower_bound']:.2f} or > {stats['upper_bound']:.2f}\")\n            print(\"â”€â”€\"*40)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:15:56.730618Z","iopub.execute_input":"2025-04-23T19:15:56.730969Z","iopub.status.idle":"2025-04-23T19:15:56.740866Z","shell.execute_reply.started":"2025-04-23T19:15:56.730945Z","shell.execute_reply":"2025-04-23T19:15:56.739763Z"}},"outputs":[],"execution_count":626},{"cell_type":"code","source":"def view_outlier_dist(df, outlier_columns):\n    for i, (col, stats) in enumerate(outlier_columns.items()):\n        if stats['percent'] > 5:\n            df_clean = df.copy()\n            df = df_clean[(df_clean[col] >= stats['lower_bound']) & (df_clean[col] <= stats['upper_bound'])]\n            \n            male_df = df_clean[df_clean['gender'] == 'male']\n            female_df = df_clean[df_clean['gender'] == 'female']\n                \n            male_stats = {'mean': male_df[col].mean(), 'std': male_df[col].std()}\n            female_stats = {'mean': female_df[col].mean(), 'std': female_df[col].std()}\n            \n            male_snr = abs(male_stats['mean']) / male_stats['std'] if male_stats['std'] != 0 else 0\n            female_snr = abs(female_stats['mean']) / female_stats['std'] if female_stats['std'] != 0 else 0\n            \n            pooled_std = np.sqrt((male_stats['std']**2 + female_stats['std']**2)/2)\n            cohens_d = abs(male_stats['mean'] - female_stats['mean']) / pooled_std\n            print(cohens_d)\n            \n            plt.figure(figsize=(12, 6))\n            \n            # Distribution plot\n            sns.kdeplot(data=df_clean, x=col, hue='gender', fill=True, alpha=0.3, \n                       common_norm=False, palette={'male':'blue', 'female':'orange'}, hue_order=('male', 'female'))\n            \n            plt.axvline(male_stats['mean'], color='blue', linestyle='--', \n                        label=f\"Male: Î¼ = {male_stats['mean']:.2f}, Ïƒ = {male_stats['std']:.2f}\")\n            plt.axvline(female_stats['mean'], color='orange', linestyle='--',\n                        label=f\"Female: Î¼ = {female_stats['mean']:.2f}, Ïƒ = {female_stats['std']:.2f}\")\n            \n            plt.axvspan(male_stats['mean'] - male_stats['std'], male_stats['mean'] + male_stats['std'], \n                        color='blue', alpha=0.1)\n            plt.axvspan(female_stats['mean'] - female_stats['std'], female_stats['mean'] + female_stats['std'],\n                       color='orange', alpha=0.1)\n            \n            plt.title(f\"{col}\\nCohen's d = {cohens_d:.2f} (Male SNR: {male_snr:.2f}, Female SNR: {female_snr:.2f})\")\n            plt.legend()\n            plt.tight_layout()\n            plt.show()\n            \n            # Print comprehensive comparison\n            print(f\"\\nðŸ“Š {col}\")\n            print(f\"   Male: Î¼/Ïƒ = {male_snr:.2f} (Î¼ = {male_stats['mean']:.2f}, Ïƒ = {male_stats['std']:.2f})\")\n            print(f\" Female: Î¼/Ïƒ = {female_snr:.2f} (Î¼ = {female_stats['mean']:.2f}, Ïƒ = {female_stats['std']:.2f})\")\n            print(f\" Standardized difference (Cohen's d): {cohens_d:.2f}\")\n            print(\"â”€â”€\"*30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:31:00.865575Z","iopub.execute_input":"2025-04-23T19:31:00.865945Z","iopub.status.idle":"2025-04-23T19:31:00.878925Z","shell.execute_reply.started":"2025-04-23T19:31:00.865920Z","shell.execute_reply":"2025-04-23T19:31:00.877783Z"}},"outputs":[],"execution_count":655},{"cell_type":"code","source":"def plot_male_female_diff(male_df, female_df):\n    for col in male_df.select_dtypes(include=np.number).columns:  # Only numeric columns\n        if col == 'gender':\n            continue\n            \n        male_stats = {'mean': male_df[col].mean(), 'std': male_df[col].std()}\n        female_stats = {'mean': female_df[col].mean(), 'std': female_df[col].std()}\n        \n        male_snr = abs(male_stats['mean']) / male_stats['std'] if male_stats['std'] != 0 else 0\n        female_snr = abs(female_stats['mean']) / female_stats['std'] if female_stats['std'] != 0 else 0\n        \n        pooled_std = np.sqrt((male_stats['std']**2 + female_stats['std']**2)/2)\n        cohens_d = abs(male_stats['mean'] - female_stats['mean']) / pooled_std\n        \n        if cohens_d > 0.4:\n            plt.figure(figsize=(12, 6))\n            \n            # Distribution plot\n            sns.kdeplot(data=df, x=col, hue='gender', fill=True, alpha=0.3, \n                       common_norm=False, palette={'male':'blue', 'female':'orange'}, hue_order=('male', 'female'))\n            \n            plt.axvline(male_stats['mean'], color='blue', linestyle='--', \n                        label=f\"Male: Î¼ = {male_stats['mean']:.2f}, Ïƒ = {male_stats['std']:.2f}\")\n            plt.axvline(female_stats['mean'], color='orange', linestyle='--',\n                        label=f\"Female: Î¼ = {female_stats['mean']:.2f}, Ïƒ = {female_stats['std']:.2f}\")\n            \n            plt.axvspan(male_stats['mean'] - male_stats['std'], male_stats['mean'] + male_stats['std'], \n                        color='blue', alpha=0.1)\n            plt.axvspan(female_stats['mean'] - female_stats['std'], female_stats['mean'] + female_stats['std'],\n                       color='orange', alpha=0.1)\n            \n            plt.title(f\"{col}\\nCohen's d = {cohens_d:.2f} (Male SNR: {male_snr:.2f}, Female SNR: {female_snr:.2f})\")\n            plt.legend()\n            plt.tight_layout()\n            plt.show()\n            \n            # Print comprehensive comparison\n            print(f\"\\nðŸ“Š {col}\")\n            print(f\"   Male: Î¼/Ïƒ = {male_snr:.2f} (Î¼ = {male_stats['mean']:.2f}, Ïƒ = {male_stats['std']:.2f})\")\n            print(f\" Female: Î¼/Ïƒ = {female_snr:.2f} (Î¼ = {female_stats['mean']:.2f}, Ïƒ = {female_stats['std']:.2f})\")\n            print(f\" Standardized difference (Cohen's d): {cohens_d:.2f}\")\n            print(\"â”€â”€\"*30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:30:53.402972Z","iopub.execute_input":"2025-04-23T19:30:53.403296Z","iopub.status.idle":"2025-04-23T19:30:53.414746Z","shell.execute_reply.started":"2025-04-23T19:30:53.403273Z","shell.execute_reply":"2025-04-23T19:30:53.413529Z"}},"outputs":[],"execution_count":654},{"cell_type":"code","source":"def plot_twenties_vs_fifties(twenties_df, fifties_df):\n    for col in twenties_df.select_dtypes(include=np.number).columns:  \n        if col == 'age':  \n            continue\n            \n        # Calculate statistics\n        twenties_stats = {'mean': twenties_df[col].mean(), 'std': twenties_df[col].std()}\n        fifties_stats = {'mean': fifties_df[col].mean(), 'std': fifties_df[col].std()}\n        \n        # Calculate signal-to-noise ratio (mean/std)\n        twenties_snr = abs(twenties_stats['mean']) / twenties_stats['std'] if twenties_stats['std'] != 0 else 0\n        fifties_snr = abs(fifties_stats['mean']) / fifties_stats['std'] if fifties_stats['std'] != 0 else 0\n        \n        # Calculate standardized mean difference (Cohen's d)\n        pooled_std = np.sqrt((twenties_stats['std']**2 + fifties_stats['std']**2)/2)\n        cohens_d = abs(twenties_stats['mean'] - fifties_stats['mean']) / pooled_std\n        \n        # Only plot if substantial difference exists (Cohen's d > 0.4 effect)\n        if cohens_d > 0.2:\n            plt.figure(figsize=(12, 6))\n            \n            # Create temp dataframe with age groups for plotting\n            plot_df = pd.concat([\n                twenties_df[col].to_frame().assign(age_group='20-29'),\n                fifties_df[col].to_frame().assign(age_group='50-59')\n            ])\n            \n            # Distribution plot\n            sns.kdeplot(data=plot_df, x=col, hue='age_group', fill=True, alpha=0.3, \n                       common_norm=False, palette={'20-29':'blue', '50-59':'orange'})\n            \n            # Add statistics annotations\n            plt.axvline(twenties_stats['mean'], color='blue', linestyle='--', \n                        label=f\"twenties: Î¼ = {twenties_stats['mean']:.2f}, Ïƒ = {twenties_stats['std']:.2f}\")\n            plt.axvline(fifties_stats['mean'], color='orange', linestyle='--',\n                        label=f\"fifties: Î¼ = {fifties_stats['mean']:.2f}, Ïƒ = {fifties_stats['std']:.2f}\")\n            \n            # Add std ranges\n            plt.axvspan(twenties_stats['mean'] - twenties_stats['std'], twenties_stats['mean'] + twenties_stats['std'], \n                        color='blue', alpha=0.1)\n            plt.axvspan(fifties_stats['mean'] - fifties_stats['std'], fifties_stats['mean'] + fifties_stats['std'],\n                       color='orange', alpha=0.1)\n            \n            plt.title(f\"{col}\\nCohen's d = {cohens_d:.2f} (twenties SNR: {twenties_snr:.2f}, fifties SNR: {fifties_snr:.2f})\")\n            plt.legend()\n            plt.tight_layout()\n            plt.show()\n            \n            # Print comprehensive comparison\n            print(f\"\\nðŸ“Š {col}\")\n            print(f\"   twenties: Î¼/Ïƒ = {twenties_snr:.2f} (Î¼ = {twenties_stats['mean']:.2f}, Ïƒ = {twenties_stats['std']:.2f})\")\n            print(f\"   fifties: Î¼/Ïƒ = {fifties_snr:.2f} (Î¼ = {fifties_stats['mean']:.2f}, Ïƒ = {fifties_stats['std']:.2f})\")\n            print(f\"   Standardized difference (Cohen's d): {cohens_d:.2f}\")\n            print(\"â”€â”€\"*30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:30:45.653604Z","iopub.execute_input":"2025-04-23T19:30:45.653983Z","iopub.status.idle":"2025-04-23T19:30:45.666127Z","shell.execute_reply.started":"2025-04-23T19:30:45.653956Z","shell.execute_reply":"2025-04-23T19:30:45.665163Z"}},"outputs":[],"execution_count":653},{"cell_type":"code","source":"def plot_age_gender_dist(twenties_df, fifties_df):\n    for col in twenties_df.select_dtypes(include=np.number).columns:\n        if col == 'age':\n            continue\n            \n        # Create subsets for each demographic group\n        male_20 = twenties_df[twenties_df['gender'] == 'male'][col].dropna()\n        male_50 = fifties_df[fifties_df['gender'] == 'male'][col].dropna()\n        female_20 = twenties_df[twenties_df['gender'] == 'female'][col].dropna()\n        female_50 = fifties_df[fifties_df['gender'] == 'female'][col].dropna()\n        \n        # Calculate all Cohen's d comparisons\n        def calculate_cohens_d(group1, group2):\n            pooled_std = np.sqrt((group1.std()**2 + group2.std()**2)/2)\n            return abs(group1.mean() - group2.mean()) / pooled_std\n        \n        cohens_d = {\n            'male_vs_female_20': calculate_cohens_d(male_20, female_20),\n            'male_vs_female_50': calculate_cohens_d(male_50, female_50),\n            'age_effect_male': calculate_cohens_d(male_20, male_50),\n            'age_effect_female': calculate_cohens_d(female_20, female_50)\n        }\n        \n        # Only plot if any comparison shows meaningful effect size\n        if any(d > 0.2 for d in cohens_d.values()):\n            plt.figure(figsize=(14, 7))\n            \n            # Create plot dataframe\n            plot_df = pd.concat([\n                male_20.to_frame().assign(group='Male 20-29'),\n                male_50.to_frame().assign(group='Male 50-59'),\n                female_20.to_frame().assign(group='Female 20-29'),\n                female_50.to_frame().assign(group='Female 50-59')\n            ])\n            \n            # Plot KDE\n            palette = {'Male 20-29':'blue', 'Male 50-59':'lightblue',\n                     'Female 20-29':'red', 'Female 50-59':'orange'}\n            \n            for group, color in palette.items():\n                group_data = plot_df[plot_df['group'] == group]\n                sns.kdeplot(data=group_data, x=col, color=color, \n                            fill=True, alpha=0.2, common_norm=False, \n                            linewidth=2, label=group)\n            \n            # Add effect size annotations\n            text_y = 0.9\n            for name, d in cohens_d.items():\n                if d > 0.2:\n                    comp_name = name.replace('_', ' ').title()\n                    plt.text(0.02, text_y, f\"{comp_name}: Cohen's d = {d:.2f}\",\n                            transform=plt.gca().transAxes, fontsize=10,\n                            bbox=dict(facecolor='white', alpha=0.7))\n                    text_y -= 0.08\n            \n            plt.title(f\"Distribution of {col}\\n(Only showing comparisons with Cohen's d > 0.2)\")\n            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n            plt.tight_layout()\n            plt.show()\n            \n            # Print detailed statistics\n            print(f\"\\nðŸ“Š {col} - Effect Size Analysis:\")\n            print(f\"  Male 20s vs Female 20s: d = {cohens_d['male_vs_female_20']:.2f}\")\n            print(f\"  Male 50s vs Female 50s: d = {cohens_d['male_vs_female_50']:.2f}\")\n            print(f\"  Age Effect (Male 20s vs 50s): d = {cohens_d['age_effect_male']:.2f}\")\n            print(f\"  Age Effect (Female 20s vs 50s): d = {cohens_d['age_effect_female']:.2f}\")\n            print(\"â”€â”€\"*40)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:30:39.461232Z","iopub.execute_input":"2025-04-23T19:30:39.462166Z","iopub.status.idle":"2025-04-23T19:30:39.475149Z","shell.execute_reply.started":"2025-04-23T19:30:39.462135Z","shell.execute_reply":"2025-04-23T19:30:39.474211Z"}},"outputs":[],"execution_count":652},{"cell_type":"code","source":"def duration_plot(male_df, female_df):\n    # Calculate statistics\n    twenties_stats = {'mean': male_df['duration'].mean(), 'std': male_df['duration'].std()}\n    fifties_stats = {'mean': female_df['duration'].mean(), 'std': female_df['duration'].std()}\n    \n    # Calculate signal-to-noise ratio (mean/std)\n    twenties_snr = abs(twenties_stats['mean']) / twenties_stats['std'] if twenties_stats['std'] != 0 else 0\n    fifties_snr = abs(fifties_stats['mean']) / fifties_stats['std'] if fifties_stats['std'] != 0 else 0\n    \n    # Calculate standardized mean difference (Cohen's d)\n    pooled_std = np.sqrt((twenties_stats['std']**2 + fifties_stats['std']**2)/2)\n    cohens_d = abs(twenties_stats['mean'] - fifties_stats['mean']) / pooled_std\n    \n    plt.figure(figsize=(12, 6))\n    \n    # Create temp dataframe with age groups for plotting\n    plot_df = pd.concat([\n        twenties_df['duration'].to_frame().assign(age_group='20-29'),\n        fifties_df['duration'].to_frame().assign(age_group='50-59')\n    ])\n    \n    # Distribution plot\n    sns.kdeplot(data=plot_df, x='duration', hue='age_group', fill=True, alpha=0.3, \n               common_norm=False, palette={'20-29':'blue', '50-59':'orange'})\n    \n    # Add statistics annotations\n    plt.axvline(twenties_stats['mean'], color='blue', linestyle='--', \n                label=f\"twenties: Î¼ = {twenties_stats['mean']:.2f}, Ïƒ = {twenties_stats['std']:.2f}\")\n    plt.axvline(fifties_stats['mean'], color='orange', linestyle='--',\n                label=f\"fifties: Î¼ = {fifties_stats['mean']:.2f}, Ïƒ = {fifties_stats['std']:.2f}\")\n    \n    # Add std ranges\n    plt.axvspan(twenties_stats['mean'] - twenties_stats['std'], twenties_stats['mean'] + twenties_stats['std'], \n                color='blue', alpha=0.1)\n    plt.axvspan(fifties_stats['mean'] - fifties_stats['std'], fifties_stats['mean'] + fifties_stats['std'],\n               color='orange', alpha=0.1)\n    \n    plt.title(f\"{col}\\nCohen's d = {cohens_d:.2f} (twenties SNR: {twenties_snr:.2f}, fifties SNR: {fifties_snr:.2f})\")\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n    \n    # Print comprehensive comparison\n    print(f\"\\nðŸ“Š duration\")\n    print(f\"   twenties: Î¼/Ïƒ = {twenties_snr:.2f} (Î¼ = {twenties_stats['mean']:.2f}, Ïƒ = {twenties_stats['std']:.2f})\")\n    print(f\"   fifties: Î¼/Ïƒ = {fifties_snr:.2f} (Î¼ = {fifties_stats['mean']:.2f}, Ïƒ = {fifties_stats['std']:.2f})\")\n    print(f\"   Standardized difference (Cohen's d): {cohens_d:.2f}\")\n    print(\"â”€â”€\"*30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:33:10.473522Z","iopub.execute_input":"2025-04-23T19:33:10.474358Z","iopub.status.idle":"2025-04-23T19:33:10.485913Z","shell.execute_reply.started":"2025-04-23T19:33:10.474330Z","shell.execute_reply":"2025-04-23T19:33:10.485122Z"}},"outputs":[],"execution_count":657},{"cell_type":"code","source":"def analyze_feature_correlations(df, threshold=0.5):\n    \n    numeric_df = df.select_dtypes(include=['number'])\n    \n    corr_matrix = numeric_df.corr()\n    \n    # Find high correlations\n    high_corr = []\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if abs(corr_matrix.iloc[i, j]) > threshold:\n                high_corr.append((corr_matrix.columns[i], corr_matrix.columns[j], \n                                 corr_matrix.iloc[i, j]))\n    return high_corr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:33:18.636525Z","iopub.execute_input":"2025-04-23T19:33:18.636884Z","iopub.status.idle":"2025-04-23T19:33:18.643222Z","shell.execute_reply.started":"2025-04-23T19:33:18.636862Z","shell.execute_reply":"2025-04-23T19:33:18.642243Z"}},"outputs":[],"execution_count":658},{"cell_type":"code","source":"def features_to_keep(all_features, corr_features, to_be_removed):\n    features_set = set()\n    to_keep = []\n    for removed in to_be_removed:\n        features_set.add(removed)\n    \n    for x, y, z in corr_features:\n        if x not in features_set and y not in features_set:\n            to_keep.append(x)\n            features_set.add(x)\n            features_set.add(y)\n\n    for feature in all_features:\n        if feature not in features_set:\n            to_keep.append(feature)\n\n    return to_keep","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:17:54.682374Z","iopub.execute_input":"2025-04-23T19:17:54.682957Z","iopub.status.idle":"2025-04-23T19:17:54.688738Z","shell.execute_reply.started":"2025-04-23T19:17:54.682927Z","shell.execute_reply":"2025-04-23T19:17:54.687732Z"}},"outputs":[],"execution_count":643},{"cell_type":"markdown","source":"## Calls","metadata":{}},{"cell_type":"code","source":"outliers_cols = find_high_outlier_columns(df)\nvisualize_outliers(df, outliers_cols)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"view_outlier_dist(df, outliers_cols)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"assert check_nulls(df) == True, 'there are nulls'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_normalized, transformations = smart_normalize(df)\noutliers_cols = find_high_outlier_columns(df_normalized)\ndf_clean = remove_outliers(df_normalized, outliers_cols)\ndf = df_clean.copy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"male_df = df[df['gender'] == 'male']\nfemale_df = df[df['gender'] == 'female']\ntwenties_df = df[df['age'] == 'twenties']\nfifties_df = df[df['age'] == 'fifties']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"correlated_features = analyze_feature_correlations(df, 0.8)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"remaining_features = features_to_keep(df.select_dtypes(include=['number']).columns, correlated_features, to_be_removed=['duration'])\nremaining_features.append('age')\nremaining_features.append('gender')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"assert len(remaining_features) == len(set(remaining_features)), 'problem in feature selection'\ndf = df[remaining_features]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Baseline Model","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.decomposition import PCA","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:18:03.994392Z","iopub.execute_input":"2025-04-23T19:18:03.995100Z","iopub.status.idle":"2025-04-23T19:18:03.999442Z","shell.execute_reply.started":"2025-04-23T19:18:03.995065Z","shell.execute_reply":"2025-04-23T19:18:03.998498Z"}},"outputs":[],"execution_count":647},{"cell_type":"code","source":"def baseline(X, y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    clf = RandomForestClassifier(random_state=42)\n    clf.fit(X_train, y_train)\n\n    y_pred = clf.predict(X_test)\n    \n    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n    print(classification_report(y_test, y_pred))\n    return clf.feature_importances_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:38:22.226295Z","iopub.execute_input":"2025-04-23T19:38:22.226746Z","iopub.status.idle":"2025-04-23T19:38:22.233510Z","shell.execute_reply.started":"2025-04-23T19:38:22.226699Z","shell.execute_reply":"2025-04-23T19:38:22.232615Z"}},"outputs":[],"execution_count":659},{"cell_type":"code","source":"X = df.drop(['gender', 'age'], axis=1)\ny = df['gender'].map({'male' : 1, 'female' : 0})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:18:04.700549Z","iopub.execute_input":"2025-04-23T19:18:04.701227Z","iopub.status.idle":"2025-04-23T19:18:04.708670Z","shell.execute_reply.started":"2025-04-23T19:18:04.701199Z","shell.execute_reply":"2025-04-23T19:18:04.707767Z"}},"outputs":[],"execution_count":648},{"cell_type":"code","source":"baseline(X, y)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pca = PCA(n_components=90)  \nX_pca = pca.fit_transform(X)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T16:51:22.067123Z","iopub.execute_input":"2025-04-23T16:51:22.067446Z","iopub.status.idle":"2025-04-23T16:51:22.146168Z","shell.execute_reply.started":"2025-04-23T16:51:22.067423Z","shell.execute_reply":"2025-04-23T16:51:22.142566Z"}},"outputs":[],"execution_count":347},{"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nplt.bar(range(pca.n_components_), pca.explained_variance_ratio_)\nplt.xlabel('Principal Component')\nplt.ylabel('Explained Variance Ratio')\nplt.title('PCA Explained Variance')\nplt.show()\n\ncumulative_variance = np.cumsum(pca.explained_variance_ratio_)\nplt.plot(cumulative_variance, marker='o')\nplt.axhline(y=0.95, color='r', linestyle='--', label='95% Variance')\nplt.xlabel('Number of Components')\nplt.ylabel('Cumulative Explained Variance')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"baseline(X, y)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = df.drop(['gender', 'age'], axis=1)\ny = df['age'].map({'twenties' : 1, 'fifties' : 0})\nbaseline(X, y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:38:47.220442Z","iopub.execute_input":"2025-04-23T19:38:47.220831Z","iopub.status.idle":"2025-04-23T19:38:56.187788Z","shell.execute_reply.started":"2025-04-23T19:38:47.220805Z","shell.execute_reply":"2025-04-23T19:38:56.186944Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.809376927822332\n              precision    recall  f1-score   support\n\n           0       0.89      0.31      0.46       424\n           1       0.80      0.99      0.88      1197\n\n    accuracy                           0.81      1621\n   macro avg       0.84      0.65      0.67      1621\nweighted avg       0.82      0.81      0.77      1621\n\n","output_type":"stream"},{"execution_count":660,"output_type":"execute_result","data":{"text/plain":"array([0.01664363, 0.00954939, 0.00891846, 0.00904001, 0.00835281,\n       0.01066492, 0.01475244, 0.01434401, 0.00871514, 0.0080285 ,\n       0.00649238, 0.00795689, 0.00748534, 0.00689819, 0.00742955,\n       0.01130259, 0.0104755 , 0.00953572, 0.01706601, 0.02395911,\n       0.00893129, 0.00718669, 0.00790893, 0.00836331, 0.01269263,\n       0.0228777 , 0.01369332, 0.01146301, 0.01642351, 0.01113599,\n       0.01070783, 0.02036954, 0.00988634, 0.01197812, 0.01248607,\n       0.00958982, 0.01145441, 0.01150285, 0.01487449, 0.00891717,\n       0.00932225, 0.00874749, 0.01054487, 0.0106987 , 0.00835294,\n       0.01008452, 0.00940933, 0.00698448, 0.0075156 , 0.00797834,\n       0.00719481, 0.00735475, 0.00655877, 0.00622104, 0.00724811,\n       0.00704689, 0.00782037, 0.00747624, 0.01069299, 0.01072026,\n       0.00709258, 0.00862228, 0.00711858, 0.00765698, 0.00864683,\n       0.00600511, 0.00694956, 0.00827101, 0.00698905, 0.00654758,\n       0.00768828, 0.00831488, 0.0086422 , 0.00863568, 0.00856146,\n       0.00774724, 0.00851685, 0.01069943, 0.00866288, 0.00834358,\n       0.00777512, 0.00906255, 0.00719226, 0.00876768, 0.00885448,\n       0.00848471, 0.0080802 , 0.00746672, 0.00838997, 0.00954562,\n       0.00806544, 0.02221947, 0.00868555, 0.00794963, 0.01163963,\n       0.00750826, 0.01090708, 0.00804592, 0.00813669, 0.00958909,\n       0.01812991, 0.00776561])"},"metadata":{}}],"execution_count":660},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T16:55:47.264451Z","iopub.execute_input":"2025-04-23T16:55:47.264851Z","iopub.status.idle":"2025-04-23T16:55:47.271759Z","shell.execute_reply.started":"2025-04-23T16:55:47.264825Z","shell.execute_reply":"2025-04-23T16:55:47.270679Z"}},"outputs":[],"execution_count":356},{"cell_type":"code","source":"df.to_csv('/kaggle/working/cleaned.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}